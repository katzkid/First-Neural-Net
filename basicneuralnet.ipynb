{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 steps:\n",
    "# Forward propogation\n",
    "# Back propogation\n",
    "# Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralnetwork:\n",
    "    #constructor\n",
    "    def __init__(self,X,Y,C,alpha,iterations):\n",
    "        m,n = X.shape\n",
    "        self.W1 = np.random.randn(C,n) * 0.01 # small ransom weights\n",
    "        self.W2 = np.random.randn(C,C) *0.01\n",
    "        self.b1 = np.zeros((C,1))\n",
    "        self.b2 = np.zeros((C,1))\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.loss_history = []\n",
    "\n",
    "    #ReLU function\n",
    "    def relu(self, X):\n",
    "        return np.maximum(0,X)\n",
    "\n",
    "    def relu_deriv(self,X):\n",
    "        return (X > 0).astype(float)\n",
    "\n",
    "    def softmax(self, X):\n",
    "        exp_X = np.exp(X - np.max(X, axis=0))  # For numerical stability\n",
    "        return exp_X / np.sum(exp_X, axis=0)\n",
    "    \n",
    "    def one_hot_encode(self, Y):\n",
    "        Y = np.array(Y).flatten()\n",
    "        # Step 1: Find the number of unique classes\n",
    "        num_classes = np.max(Y) + 1  # Assumes labels are 0-indexed; adjust if not\n",
    "        # Step 2: Create a zero matrix for one-hot encoding\n",
    "        Y_one_hot = np.zeros((Y.size, num_classes))\n",
    "        # Step 3: Set appropriate elements to 1\n",
    "        Y_one_hot[np.arange(Y.size), Y] = 1\n",
    "        return Y_one_hot\n",
    "    \n",
    "    # Cross-entropy loss function\n",
    "    def compute_loss(self, A2, Y):\n",
    "        Y_one_hot = self.one_hot_encode(Y)\n",
    "        # Using np.clip to avoid log(0)\n",
    "        A2_clipped = np.where(A2 > 1e-12, A2, 1e-12)  # Clip values below 1e-12\n",
    "        loss = -np.mean(np.sum(Y_one_hot.T * np.log(A2_clipped), axis=1))\n",
    "        return loss\n",
    "    \n",
    "    def accuracy(self, Y, Y_pred):\n",
    "        Y = Y.flatten()\n",
    "        return np.mean(Y == Y_pred)\n",
    "    \n",
    "    # Forward propogation\n",
    "    def forward_propogation(self, X):\n",
    "        A0 = X\n",
    "        Z1 = self.W1@A0.T + self.b1\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = self.W2@A1 + self.b2\n",
    "        A2 = self.softmax(Z2)\n",
    "        return Z1, A1, Z2, A2\n",
    "\n",
    "    #back propogation\n",
    "    def back_propogation(self, A2, Y, A1, X, Z1):\n",
    "        Y_one_hot = self.one_hot_encode(Y)\n",
    "        dZ2 = A2 - Y_one_hot.T # Y here is one hot encoded\n",
    "        dW2 = (dZ2@A1.T)/self.m\n",
    "        db2 = np.sum(dZ2,axis=1).reshape(-1,1)/self.m\n",
    "        dA1 = self.W2@dZ2\n",
    "        dZ1 = dA1*self.relu_deriv(Z1) #Element wise multiplication\n",
    "        dW1 = (dZ1@X)/self.m\n",
    "        db1 = np.sum(dZ1,axis=1).reshape(-1,1)/self.m\n",
    "        return dW1, dW2, db1, db2\n",
    "    \n",
    "    def update_params(self, dW1, dW2, db1, db2):\n",
    "        self.W1 = self.W1 - self.alpha*dW1\n",
    "        self.W2 = self.W2 - self.alpha*dW2\n",
    "        self.b2 = self.b2 - self.alpha*db2\n",
    "        self.b1 = self.b1 - self.alpha*db1\n",
    "\n",
    "    def predict(self, A2):\n",
    "        return np.argmax(A2, axis=0)\n",
    "\n",
    "    def gradientdescent(self, X, Y):\n",
    "        for i in range(self.iterations):\n",
    "            Z1, A1, Z2, A2 = self.forward_propogation(X=X)\n",
    "            dW1, dW2, db1, db2 = self.back_propogation(A2, Y, A1, X, Z1)\n",
    "            self.update_params(dW1, dW2, db1, db2)\n",
    "\n",
    "            # Calculate and store loss\n",
    "            loss = self.compute_loss(A2, Y)\n",
    "            self.loss_history.append(loss)\n",
    "            if i%10==0:\n",
    "                print(f\"Iteration {i}: Loss = {loss:.4f}\")\n",
    "                Y_pred = self.predict(A2)\n",
    "                print(f'Accuracy: {self.accuracy(Y, Y_pred) * 100:.2f}%')\n",
    "                \n",
    "    def test_prediction(self, index, X, Y):\n",
    "        current_image = X[index,:]\n",
    "        prediction = self.make_predictions(X[index,:].reshape(-1,1).T)\n",
    "        label = Y[index]\n",
    "        print(\"Prediction: \", prediction)\n",
    "        print(\"Label: \", label)\n",
    "        \n",
    "        current_image = current_image.reshape((28, 28)) * 255\n",
    "        plt.gray()\n",
    "        plt.imshow(current_image, interpolation='nearest')\n",
    "        plt.show()\n",
    "\n",
    "    def make_predictions(self,X):\n",
    "        print('Shape of X', X.shape)\n",
    "        _, _, _, A2 = self.forward_propogation(X=X)\n",
    "        print('Shape A2', A2.shape)\n",
    "        predictions = self.predict(A2)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training data set\n",
    "train_data = pd.read_csv('train.csv')\n",
    "np.random.shuffle(np.array(train_data)) # shuffle before splitting into dev and training sets\n",
    "train_data.head()\n",
    "m,n = train_data.shape\n",
    "X_train = train_data.iloc[:,1:n].to_numpy()/255\n",
    "Y_train = train_data.iloc[:,0].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 9670.9892\n",
      "Accuracy: 8.58%\n",
      "Iteration 10: Loss = 9669.5261\n",
      "Accuracy: 11.15%\n",
      "Iteration 20: Loss = 9667.7318\n",
      "Accuracy: 11.15%\n",
      "Iteration 30: Loss = 9664.7436\n",
      "Accuracy: 11.15%\n",
      "Iteration 40: Loss = 9659.1816\n",
      "Accuracy: 11.15%\n",
      "Iteration 50: Loss = 9648.8793\n",
      "Accuracy: 11.84%\n",
      "Iteration 60: Loss = 9630.6619\n",
      "Accuracy: 17.82%\n",
      "Iteration 70: Loss = 9598.5329\n",
      "Accuracy: 26.89%\n",
      "Iteration 80: Loss = 9539.8418\n",
      "Accuracy: 34.96%\n",
      "Iteration 90: Loss = 9432.3182\n",
      "Accuracy: 36.36%\n",
      "Iteration 100: Loss = 9241.5037\n",
      "Accuracy: 35.25%\n",
      "Iteration 110: Loss = 8926.4521\n",
      "Accuracy: 35.00%\n",
      "Iteration 120: Loss = 8456.5295\n",
      "Accuracy: 38.17%\n",
      "Iteration 130: Loss = 7826.4929\n",
      "Accuracy: 49.02%\n",
      "Iteration 140: Loss = 7071.6988\n",
      "Accuracy: 59.89%\n",
      "Iteration 150: Loss = 6278.4309\n",
      "Accuracy: 65.38%\n",
      "Iteration 160: Loss = 5548.9843\n",
      "Accuracy: 68.43%\n",
      "Iteration 170: Loss = 4942.6761\n",
      "Accuracy: 70.97%\n",
      "Iteration 180: Loss = 4463.5596\n",
      "Accuracy: 73.08%\n",
      "Iteration 190: Loss = 4088.2070\n",
      "Accuracy: 74.78%\n",
      "Iteration 200: Loss = 3790.4464\n",
      "Accuracy: 76.23%\n",
      "Iteration 210: Loss = 3549.4924\n",
      "Accuracy: 77.37%\n",
      "Iteration 220: Loss = 3350.6909\n",
      "Accuracy: 78.34%\n",
      "Iteration 230: Loss = 3183.7631\n",
      "Accuracy: 79.13%\n",
      "Iteration 240: Loss = 3041.2269\n",
      "Accuracy: 79.91%\n",
      "Iteration 250: Loss = 2917.6977\n",
      "Accuracy: 80.65%\n",
      "Iteration 260: Loss = 2809.1612\n",
      "Accuracy: 81.34%\n",
      "Iteration 270: Loss = 2712.6133\n",
      "Accuracy: 81.87%\n",
      "Iteration 280: Loss = 2625.7827\n",
      "Accuracy: 82.45%\n",
      "Iteration 290: Loss = 2547.0055\n",
      "Accuracy: 82.95%\n",
      "Iteration 300: Loss = 2475.0087\n",
      "Accuracy: 83.49%\n",
      "Iteration 310: Loss = 2408.8534\n",
      "Accuracy: 83.88%\n",
      "Iteration 320: Loss = 2347.8084\n",
      "Accuracy: 84.38%\n",
      "Iteration 330: Loss = 2291.2836\n",
      "Accuracy: 84.70%\n",
      "Iteration 340: Loss = 2238.8422\n",
      "Accuracy: 85.10%\n",
      "Iteration 350: Loss = 2190.1340\n",
      "Accuracy: 85.46%\n",
      "Iteration 360: Loss = 2144.8681\n",
      "Accuracy: 85.74%\n",
      "Iteration 370: Loss = 2102.7704\n",
      "Accuracy: 86.04%\n",
      "Iteration 380: Loss = 2063.5585\n",
      "Accuracy: 86.31%\n",
      "Iteration 390: Loss = 2026.9865\n",
      "Accuracy: 86.57%\n",
      "Iteration 400: Loss = 1992.8322\n",
      "Accuracy: 86.75%\n",
      "Iteration 410: Loss = 1960.8861\n",
      "Accuracy: 86.90%\n",
      "Iteration 420: Loss = 1930.9444\n",
      "Accuracy: 87.11%\n",
      "Iteration 430: Loss = 1902.8347\n",
      "Accuracy: 87.30%\n",
      "Iteration 440: Loss = 1876.3845\n",
      "Accuracy: 87.45%\n",
      "Iteration 450: Loss = 1851.4257\n",
      "Accuracy: 87.60%\n",
      "Iteration 460: Loss = 1827.8344\n",
      "Accuracy: 87.75%\n",
      "Iteration 470: Loss = 1805.4809\n",
      "Accuracy: 87.88%\n",
      "Iteration 480: Loss = 1784.2508\n",
      "Accuracy: 88.01%\n",
      "Iteration 490: Loss = 1764.0663\n",
      "Accuracy: 88.14%\n"
     ]
    }
   ],
   "source": [
    "myNN = neuralnetwork(X_train, Y_train, C=10, alpha=0.1, iterations=500)\n",
    "myNN.gradientdescent(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (1, 784)\n",
      "Shape A2 (10, 1)\n",
      "Prediction:  [4]\n",
      "Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myNN.test_prediction(99, X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab2python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
